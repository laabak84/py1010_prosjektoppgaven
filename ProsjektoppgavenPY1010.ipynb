{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0d62a-bbc7-413f-b5a3-0bbaf4e34240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Prosjektoppgave PY1010\n",
    "\n",
    " Skrevet av Daniel Dale Laabak\n",
    " Vår 2025\n",
    "\n",
    " Programmet henter data om berammede rettssaker i rettssystemet i Norge og gir en oversikt over\n",
    " de sakene som er berammet i samtlige tingretter, lagmannsretter og høyesterett  i datointervallet brukeren velger.\n",
    "\n",
    " Da det alltid er en fare for at API på nettsidene til domstol kan endre seg, er en fallback-løsning\n",
    " å hente dataene fra en lagret fil som har korrekt format, saker.csv . Denne filen følger også prosjekt-\n",
    " oppgaven, og programmet faller tilbake på denne filen dersom web-api ikke er mulig å hente fra. \n",
    "\n",
    " Domstolene har en bra åpen oversikt over berammede saker, men sier ingenting om antall saker av en\n",
    " viss type, eller antall saker som er til behandling ved de ulike domstolene. Som journalist eller som \n",
    " interessert i saker som er til behandling i rettsvesenet vil dette kunne gi en god oversikt over sakene\n",
    " som til enhver tid er til behandling i retssystemet. \n",
    "\n",
    " Domstolene har ikke noe offisielt API. APIet er funnet ved å besøke nettsiden til domstol.no, og inspisere\n",
    " hva nettleseren faktisk gjør når man søker på berammede saker i domstolene. En slik løsning innebærer derfor\n",
    " alltid risiko for at noe kan endre seg.\n",
    "\n",
    " BESKRIVELSE AV RETUR FRA API:\n",
    "APIet gir svar i json-format, og svaret ser slik ut (eksempel):\n",
    "\n",
    "EKSEMPEL START\n",
    "{\n",
    "  \"FormData\": {\n",
    "    \"From\": \"2025-04-19T00:00:00\",\n",
    "    \"To\": \"2099-04-19T00:00:00\",\n",
    "    \"Periode\": \"\",\n",
    "    \"Court\": \"\",\n",
    "    \"CourtName\": \"Alle domstoler\",\n",
    "    \"CourtValue\": \"\",\n",
    "    \"AdvancedSearch\": false,\n",
    "    \"CaseAbout\": \"\",\n",
    "    \"CaseNumber\": \"\",\n",
    "    \"Page\": 1,\n",
    "    \"PageSize\": 1000,\n",
    "    \"sortAscending\": true,\n",
    "    \"sortTerm\": \"startdato\"\n",
    "  },\n",
    "  \"hits\": [\n",
    "    {\n",
    "      \"id\": \"164514\",\n",
    "      \"embeteId\": \"AAAA2103101754092672012RXHZEG_EJBOrgUnit\",\n",
    "      \"startdato\": \"2025-04-19T08:00:00\",\n",
    "      \"sluttdato\": \"2025-04-19T08:50:00\",\n",
    "      \"domstol\": \"Søndre Østfold tingrett\",\n",
    "      \"saksnummer\": \"25-063575ENE-TSOS/TSAR\",\n",
    "      \"sakenGjelder\": \"førstegangsfengsling\",\n",
    "      \"parter\": null\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "EKSEMPEL SLUTT\n",
    "\n",
    "\n",
    "Videre avleder vi sakstype fra saksnummeret, da feltet \"sakenGjelder\" ovenfor er et fritekstfelt, og inneholder\n",
    "veldig mange ulike verdier. For dette programmet har vi valgt å bare inkludere sakstypene som følger mønsteret nedenfor:\n",
    "\"ENE-\", \"TVI-\", \"TVA-\", \"MED-\", \"KON-\", \"ASD-\", \"AST-\", \"STR-HRET\", \"SIV-HRET\", \"ASK-\", \"DBO-\", \"GJE-\", \"REN-\", \"RFA-\", \"SAM-\", \"SKJ-\".\n",
    "\n",
    "En egen forklaring om hva de ulike sakstypene omfatter, fremkommer i slutten av programmet når programmet kjøres.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f836e0-38f1-401e-8ecb-f91767980934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Først importerer vi nødvendige biblioteker for å kjøre programmet:\n",
    "import os #for å lese filer\n",
    "import requests #for å kunne hente data fra domstol.no\n",
    "import csv #for å lese og skrive filer\n",
    "from datetime import datetime,timedelta #for å håndtere datoer og å trekke fra/legge til dager\n",
    "import pandas as pd #for å lage dataframes\n",
    "import matplotlib.pyplot as plt #for å lage plott og diagrammer\n",
    "\n",
    "\"\"\"\n",
    "EGEN BOLK FOR FUNKSJONER OG FASTE VARIABLER\n",
    "\"\"\"\n",
    "# Vi starter så programmet med å angi såkalt \"base\"-URL for å hente inn sakene fra APIet til domstol.no:\n",
    "BASE_URL = \"https://www.domstol.no/api/episerver/v3/beramming\"\n",
    "\n",
    "# Vi angir så navnet på CSV-filen. Det følger en standard-fil med prosjektet. Brukeren kan velge mellom å bruke filen \n",
    "# som allerede finnes, eller om brukeren vil laste nye data og overskrive filen.\n",
    "CSV_FILENAME = \"saker.csv\"\n",
    "\n",
    "# Vi setter variabelen valg til None, slik at det ikke er gjort noe valg på forhånd, og slik at variabelen finnes.\n",
    "# Dette gjør at variabelen er initialisert når vi skal sjekke verdien senere i koden.\n",
    "valg = None\n",
    "\n",
    "# Fordi APIet ikke gir sakstyper, har jeg laget en oversikt som en liste, som viser de ulike sakstypene APIet \n",
    "# kan returnere. Sakstypene baserer seg på en del av saksnummeret, normalt karakter 10,11 og 12 i saksnummeret. \n",
    "# Unntaket fra hovedregelen er saker for Norges Høyesterett, vi har derfor med karakterene 13-17 fra saksnummeret for \n",
    "# sakene som gjelder Norges Høyesterett.\n",
    "explanations = {\n",
    "            \"ENE-\": \"Enedommersaker\",\n",
    "            \"TVI-\": \"Tvistesaker\",\n",
    "            \"TVA-\": \"Tvangssaker\",\n",
    "            \"MED-\": \"Meddommersaker\",\n",
    "            \"ASD-\": \"Ankesak, dom\",\n",
    "            \"AST-\": \"Andre ankesaker\",\n",
    "            \"KON-\": \"Konkurssaker\",\n",
    "            \"STR-HRET\": \"Straffesak, Høyesterett\",\n",
    "            \"SIV-HRET\": \"Sivil sak, Høyesterett\",\n",
    "            \"ASK-\": \"Ankesak, kjennelse\",\n",
    "            \"DBO-\": \"Skiftesak\",\n",
    "            \"GJE-\": \"Gjeldsordning\",\n",
    "            \"REN-\": \"Rettsendrende sak\",\n",
    "            \"RFA-\": \"Rettsfastsettende sak\",\n",
    "            \"SAM-\": \"Samlivssak\",\n",
    "            \"SKJ-\": \"Skjønnssak\",\n",
    "            \"Annet\": \"Andre sakstyper\"\n",
    "            \n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Vi bygger så funksjonen for å hente første side fra domstol.no sitt API, med parametere.\n",
    "# Input til funksjonen er fra-dato, til-dato, sidenummer, antall treff pr. side\n",
    "# Fra- og til dato settes automatisk til 14 dager før dagens dato, og frem til 2099 for å hente samtlige saker.\n",
    "def fetch_page(from_date: str, to_date: str, page: int, page_size: int = 1000):\n",
    "\n",
    "    params = {\n",
    "        \"fraDato\": from_date,\n",
    "        \"tilDato\": to_date,\n",
    "        \"page\": page,\n",
    "        \"pageSize\": page_size,\n",
    "        \"sortTerm\": \"startdato\",\n",
    "        \"sortAscending\": \"true\",\n",
    "    }\n",
    "    resp = requests.get(BASE_URL, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data.get(\"hits\", [])\n",
    "\n",
    "# Deretter bygger vi funksjonen for å løpe gjennom alle sidene i APIet for å hente resten av sakene fra APIet\n",
    "def fetch_all_cases(from_date: str, to_date: str):\n",
    "    all_cases = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        hits = fetch_page(from_date, to_date, page)\n",
    "        if not hits:\n",
    "            break\n",
    "        all_cases.extend(hits)\n",
    "        print(f\"Hentet side {page}, saker totalt: {len(all_cases)}\")\n",
    "        page += 1\n",
    "    return all_cases\n",
    "\n",
    "# Deretter bygger vi funksjonen for å lagre alle sakene til CSV, slik at vi har dataene i en fil, og senere \n",
    "# kan gjenbruke dataene fra filen, og unngå å belaste APIet unødvendig. Filename er angitt som variabel tidligere i\n",
    "# programmet.\n",
    "def save_to_csv(cases: list, filename: str):\n",
    "    if not cases:\n",
    "        print(f\"Ingen saker å lagre for oppgitt datointervall.\")\n",
    "        return\n",
    "    keys = cases[0].keys()\n",
    "    with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(cases)\n",
    "    print(f\"Lagret {len(cases)} saker til {filename}\")\n",
    "\n",
    "# Deretter bygger vi funksjonen for å viser vi saker pr. domstol i et stolpediagram(plott), filtrert på navnet på domstolen ved å bruke mask, \n",
    "# slik at vi når vi kaller funksjonen kan angi \"Tingrett\", \"Lagmannsrett\" eller \"Høysterett\". Andre domstoler ville man også kunne\n",
    "# angi med f.eks \"Jordskifterett\", men dette programmet viser bare saker for tingrettene, lagmannsrettene og høyesterett.\n",
    "def plot_cases_per_court(df, court, date_from, date_to):\n",
    " \n",
    "    mask = df['domstol'].str.contains(court, case=False, na=False)\n",
    "    counts = df.loc[mask, 'domstol'].value_counts()\n",
    "\n",
    "    if counts.empty:\n",
    "        print(f\"Ingen {court}-saker fra {date_from} til {date_to}\")\n",
    "        return\n",
    "\n",
    "    ax = counts.plot(kind='bar', figsize=(12, 6))\n",
    "    ax.set_xlabel('Domstol')\n",
    "    ax.set_ylabel('Antall saker')\n",
    "    ax.set_title(f\"Saker per {court} for periode {date_from} til {date_to}\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# For å vise både antall saker og antall prosent av totalen hver kategori/sakstype i kakediagrammet, lager vi en funksjon \n",
    "# som beregner hvor mange prosent det aktuelle typen utgjør av totalen.\n",
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        count = int(round(pct * total / 100.0))\n",
    "        return f\"{count}\\n({pct:.1f}%)\"\n",
    "    return my_autopct\n",
    "\n",
    "# Deretter bygger vi funksjonen for å viser vi saker pr. sakstype i et kakediagram(plott), filtrert på sakstypen ved å bruke mask, \n",
    "# basert på de ulike sakstypene avledet fra sasksnummeret som er definert i variablen keywords. Saker som ikke inngår i de angitte\n",
    "# Sakstypene, filtreres ut og klassifiseres som \"Annet\". Som input har vi en minimum-prosent for å gjøre kakediagrammet mer oversiktlig\n",
    "# hvor vi putter alle typer som utgjør mindre enn 2,5% (0.025) av totalen i en kategori som vi kaller \"Andre sakstyper\". Til slutt \n",
    "# Skriver vi ut en forklaring for hva de ulike sakstypene er.\n",
    "def plot_cases_sakstyper(df, min_pct=0.025):\n",
    "    df = df.copy()\n",
    "    keywords = [\"ENE-\", \"TVI-\", \"TVA-\", \"MED-\", \"KON-\", \"ASD-\", \"AST-\",\n",
    "                \"STR-HRET\", \"SIV-HRET\", \"ASK-\", \"DBO-\", \"GJE-\",\n",
    "                \"REN-\", \"RFA-\", \"SAM-\", \"SKJ-\"]\n",
    "\n",
    "    def hent_sakstype(s):\n",
    "        s = str(s).upper()\n",
    "        for kw in keywords:\n",
    "            if kw in s:\n",
    "                return kw.rstrip('-')\n",
    "        return 'Annet'\n",
    "\n",
    "    df['sakstype'] = df['saksnummer'].apply(hent_sakstype)\n",
    "\n",
    "    counts = df['sakstype'].value_counts()\n",
    "    total = counts.sum()\n",
    "\n",
    "    mask = (counts / total) >= min_pct\n",
    "    counts_large = counts[mask].copy()\n",
    "    others_sum = counts[~mask].sum()\n",
    "    if others_sum > 0:\n",
    "        counts_large['Andre sakstyper'] = others_sum\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    counts_large.plot(\n",
    "        kind='pie', ax=ax, labels=None,\n",
    "        autopct=make_autopct(counts_large),\n",
    "        startangle=90, labeldistance=1.1\n",
    "    )\n",
    "    ax.set_ylabel('')\n",
    "    ax.axis('equal')\n",
    "    ax.legend(\n",
    "        counts_large.index, title=\"Sakstype\",\n",
    "        loc='center left', bbox_to_anchor=(1.0, 0.5)\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #Skriv ut forklaringer for hver av sakstypene (med og uten - fordi strukturen er ulik).\n",
    "    print(\"\\nForklaringer for sakstyper:\")\n",
    "    for kode in counts.index:\n",
    "        if kode in explanations:\n",
    "            tekst = explanations[kode]\n",
    "        else:\n",
    "            tekst = explanations.get(kode + '-', \"Ingen forklaring tilgjengelig\")\n",
    "        print(f\"  {kode}: {tekst}\")\n",
    "\n",
    "\"\"\"\n",
    "SLUTT PÅ FUNKSJONER OG FASTE VARIABLER\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "START PÅ KJØRINGEN AV PROGRAMMET\n",
    "\"\"\"\n",
    "# Først sjekker programmet om filen finnes. Den leses inn hvis den finnes, den sjekker antall rader i filen\n",
    "# og når filen sist ble lagret. Brukeren blir presentert med et valg om å bruke data fra filen eller å hente \n",
    "# inn nye data. Dersom filen ikke finnes, blir brukeren tatt videre til neste steg - valg 2 som er å hente nye\n",
    "# data inn til saker.csv. \n",
    "\n",
    "# Leser inn filen hvis den finnes, vis antall og når den ble lagret\n",
    "if os.path.exists(CSV_FILENAME):\n",
    "    df_saved = pd.read_csv(CSV_FILENAME, parse_dates=['startdato'], dayfirst=False)\n",
    "    n_saved = len(df_saved)\n",
    "    saved_time = datetime.fromtimestamp(os.path.getmtime(CSV_FILENAME))\n",
    "    print(f\"Funnet {CSV_FILENAME} med {n_saved} rader, sist lagret {saved_time:%Y-%m-%d %H:%M}\")\n",
    "    valg = input(\"1) Bruk lagrede saker 2) Hent nye saker (1/2): \")\n",
    "\n",
    "# Hvis filen ikke finnes, settes valg til 2, og brukeren får beskjed om at nye data hentes inn.\n",
    "else:\n",
    "    print(\"Det finnes ingen lokalt lagret fil, vi henter derfor nye data fra Domstol.no sitt API.\")\n",
    "    valg = '2'\n",
    "\n",
    "while valg not in ('1','2'):\n",
    "    valg = input(\"Du angav ugyldig valg. Du må velge 1 eller 2!\\nVelg på nytt: \\n1) Bruk lagrede saker 2) Hent nye saker (1/2): \")\n",
    "\n",
    "\n",
    "# Hvis brukeren velger 1 - altså å bruke eksisterende fil, gis brukeren mulighet til å filtrere søket på egne\n",
    "# valgte datoer fra CSV-filen, basert på laveste (min_date) startdato og høyeste (max_date) sluttdato i csv-filen.\n",
    "if valg == '1':\n",
    "    # La bruker filtrere på datoer innenfor eksisterende fil\n",
    "    min_date = df_saved['startdato'].dt.date.min()\n",
    "    max_date = df_saved['startdato'].dt.date.max()\n",
    "    print(f\"Filtrér mellom {min_date} og {max_date}. Dersom du trykker enter/retur, vil du beholde laveste \\ndato og høyeste dato i datasettet.\")\n",
    "    inp_from = input(f\"Fra-dato [{min_date}]: \").strip() or str(min_date)\n",
    "    inp_to   = input(f\"Til-dato [{max_date}]: \").strip() or str(max_date)\n",
    "\n",
    "    # Sørg for at datointervall er innenfor\n",
    "    d_from = max(datetime.fromisoformat(inp_from).date(), min_date)\n",
    "    d_to   = min(datetime.fromisoformat(inp_to).date(),   max_date)\n",
    "\n",
    "    print(f\"Bruker lagrede saker filtrert: {d_from} til {d_to}\")\n",
    "    # Filtrer dataframe (df)\n",
    "    df = df_saved[\n",
    "        (df_saved['startdato'].dt.date >= d_from) &\n",
    "        (df_saved['startdato'].dt.date <= d_to)\n",
    "    ].copy()\n",
    "\n",
    "# Hvis 2 er valgt, henter programmet automatisk samtlige saker som er tilgjengelige fra APIet. APIet tilbyr saker fra 14 dager\n",
    "# tilbake i tid, og ubegrenset fremover i tid. Vi setter derfor startdatoen til 14 dager før dagens dato,\n",
    "# og sluttdatoen til 2099, slik at vi henter inn samtlige saker som er tilgjengelige i APIet. \n",
    "# Dersom brukeren opererer i en annen tidssone enn oss, vil forespørselen kunne feile, ettersom APIet gir en feilmelding som\n",
    "# vi velger å ikke håndtere for dette prosjektets del, dersom man forsøker å spørre mer enn 14 dager tilbake i tid.\n",
    "# TODO: Lage feilhåndtering basert på tilbakemelding fra APIet. \n",
    "else:\n",
    "    # Hent nye saker: standard første kjøring 14 dager tilbake i tid frem til utgangen av år 2099\n",
    "    inp_from = (datetime.now() - timedelta(days=14)).strftime('%Y-%m-%d')\n",
    "    inp_to   = '2099-12-31'\n",
    "\n",
    "    #Skriv ut informasjon mens sakene hentes\n",
    "    print(f\"Henter data fra {inp_from} til {inp_to}\")\n",
    "    cases = fetch_all_cases(inp_from, inp_to)\n",
    "    #Lagre sakene til CSV\n",
    "    save_to_csv(cases, CSV_FILENAME)\n",
    "\n",
    "    # Les inn CSV på nytt \n",
    "    df = pd.read_csv(CSV_FILENAME, parse_dates=['startdato'], dayfirst=False)\n",
    "    \n",
    "    # La bruker filtrere på datoer innenfor eksisterende csv-fil\n",
    "    min_date = df['startdato'].dt.date.min()\n",
    "    max_date = df['startdato'].dt.date.max()\n",
    "    print(f\"Filtrér mellom {min_date} og {max_date}. Dersom du trykker enter/retur, vil du beholde laveste \\ndato og høyeste dato i datasettet.\")\n",
    "    inp_from = input(f\"Fra-dato [{min_date}]: \").strip() or str(min_date)\n",
    "    inp_to   = input(f\"Til-dato [{max_date}]: \").strip() or str(max_date)\n",
    "    d_from = datetime.fromisoformat(inp_from).date()\n",
    "    d_to   = datetime.fromisoformat(inp_to).date()\n",
    "\n",
    "    # Filtrer også her på valgte datoer\n",
    "    df = df[\n",
    "        (df['startdato'].dt.date >= d_from) &\n",
    "        (df['startdato'].dt.date <= d_to)\n",
    "    ].copy()\n",
    "\n",
    "#Til slutt kaller vi funksjonene med datointervaller og navn (Tingrett/Lagmannsrett/Høyesterett)\n",
    "plot_cases_per_court(df, \"Tingrett\", d_from, d_to)\n",
    "plot_cases_per_court(df, \"Lagmannsrett\", d_from, d_to)\n",
    "plot_cases_per_court(df, \"Høyesterett\", d_from, d_to)\n",
    "plot_cases_sakstyper(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
